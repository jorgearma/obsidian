# üõ°Ô∏è **Hallazgo: Acceso no autenticado y endpoints inefectivos en evaluator.py**

## **Severidad**

**Moderada** ‚Äì Aunque no es posible modificar la personalidad o el comportamiento del agente IA debido a que el prompt est√°tico se carga desde un archivo interno, el endpoint carece de autenticaci√≥n y permite generar PDFs y acceder a informaci√≥n de otros usuarios sin restricci√≥n. Esto abre la puerta a corrupci√≥n de PDFs, posibles cargas maliciosas en documentos y exposici√≥n de informaci√≥n sensible. El impacto real es limitado, pero el riesgo conceptual y la violaci√≥n de confidencialidad lo elevan a severidad moderada.
## **1. Descripci√≥n del fallo**

El archivo `evaluator.py y instruction.py` expone varios endpoints que permiten:

- Evaluar contenido mediante un agente IA.
    
- Cambiar la personalidad del agente.
    
- Restaurar la personalidad a valores por defecto.
    

Sin embargo:

### ‚úÖ La personalidad REAL del agente **no se obtiene desde la base de datos**

La IA usa un _prompt est√°tico_ embebido en un archivo `.py` del proyecto.

### ‚ùå Pero los endpoints que permiten modificar la personalidad **no requieren autenticaci√≥n**

Cualquier usuario externo puede llamar:

- `/instruction GET`  
    
- `/instruction POST cambia instruciones de MIA
    
- `/evaluate`
    

‚Ä¶y la API lo aceptar√°, aunque **estos cambios NO afectan al funcionamiento real de la IA**, porque el agente carga su configuraci√≥n desde un archivo local del backend.

El resultado es:

### ‚Üí **Los endpoints quedan expuestos, pero no tienen efecto real.**

---

## **2. Impacto**

### **Impacto real bajo**, pero con riesgo conceptual:

- Un atacante puede ejecutar comandos sobre endpoints sensibles **sin autenticarse**.
    
- Puede generar confusi√≥n al administrador y registros falsos.
    
- Puede provocar un **DoS l√≥gico** (sobrecarga de peticiones innecesarias).
    
- Puede inducir a pensar que la IA cambi√≥ su personalidad cuando no es as√≠.
    
- Se revela un dise√±o inseguro: endpoints cr√≠ticos sin autenticaci√≥n.
    

### **No existe riesgo de Prompt Injection persistente**, porque:

- La IA **no usa la base de datos** para cargar su personalidad.
    
- El prompt fijo en el archivo `.py` no puede ser modificado por la API.
    

Por tanto, **no se puede alterar realmente el comportamiento del agente**.


## **3. Evaluaci√≥n de grupos sin autenticaci√≥n**

El endpoint `/evaluate` **no requiere autenticaci√≥n ni autorizaci√≥n**, lo que significa que **cualquier usuario externo puede invocar el servicio** para:

- Solicitar evaluaciones de cualquier grupo (`group_id`).
    
- Generar PDFs de evaluaci√≥n de otros usuarios.
    
- Acceder a informaci√≥n parcial de grupos, aunque no sean los propietarios.
    

### Riesgos asociados:

- **Exposici√≥n de informaci√≥n sensible**: nombres de estudiantes, c√©dulas, programas y evaluaciones.
    
- **Corrupci√≥n o manipulaci√≥n de PDFs**: un atacante podr√≠a inyectar contenido malicioso o informaci√≥n falsa en los PDFs generados.
    
- **Uso indebido del servicio**: un actor externo podr√≠a automatizar peticiones masivas, generando carga en el sistema y confundiendo registros.
    
- **Fuga de informaci√≥n indirecta**: aunque la IA no cambia su comportamiento, los datos de entrada (conversaciones) podr√≠an contener informaci√≥n sensible y ser devueltos en el PDF.

> Nota: Todas las recomendaciones deben aplicarse primero en un entorno de prueba antes de pasar a producci√≥n para evitar corrupci√≥n de datos.